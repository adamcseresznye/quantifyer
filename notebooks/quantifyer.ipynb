{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5cdfc-0fe4-452f-adf7-7df5191141d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "import common_operations\n",
    "import data\n",
    "import qc\n",
    "import recovery\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bcdb46-b093-41d7-9627-6b0ecd55cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock_peak_areas = \"name,type,QC_1,QC_2,QC_3,QC_4,QC_5,ISRS_1,ISRS_2,ISRS_3,ISRS_4,ISRS_5\\n13C_HCB,Area,20,40,60,80,100,20,40,60,80,100\\nCB_207,Area,100,100,100,100,100,1000,1000,1000,1000,1000\"\n",
    "# mock_is_concentration_file = \"name,amount\\n13C_HCB,1000\\nCB_207,1000\"\n",
    "# mock_sample_properties_file = \"sample_name,sample_type,volume\\nQC_1,qc,0.5\\nQC_2,qc,0.5\\nQC_3,qc,0.5\\nQC_4,qc,0.5\\nQC_5,qc,0.5\\nISRS_1,isrs,0.5\\nISRS_2,isrs,0.5\\nISRS_3,isrs,0.5\\nISRS_4,isrs,0.5\\nISRS_5,isrs,0.5\"\n",
    "# mock_is_correspondence_file = (\n",
    "#     \"native,internal_standard,external_standard\\nalpaHCH,13C_HCB,CB_207\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d703f6-8b51-4ce0-a606-55a828cfec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = utils.Configuration.RAW_DATA_PATH\n",
    "\n",
    "df = data.Data(\n",
    "    quant_file=parent_folder.joinpath(\"results.csv\"),\n",
    "    is_correspondence_file=parent_folder.joinpath(\"is_std_table_correspondence.csv\"),\n",
    "    sample_properties_file=parent_folder.joinpath(\"sample_properties.csv\"),\n",
    "    qc_file=parent_folder.joinpath(\"qc.csv\"),\n",
    "    is_concentration_file=parent_folder.joinpath(\"is_std_table_concentration.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab03f16-7a14-4d85-98a4-567b3ac411ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.DataValidator(df).validate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075dd1a-9be4-48e6-8a46-de0907e6f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_operations.BaseCalculator(df).get_is_rs_amount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef54e3-b911-4db8-b268-cd826a3daa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047695ce-d844-4e62-820b-0549d956cfde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b606833-1137-413f-b2ba-7b508333573c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be82e20-b2f7-4f02-80f2-e901c7dd17e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550359dd-f08e-4c10-a5be-fa7303fda44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee2cea-0d5e-41e2-861b-fe84b1cb16a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a975f143-f470-4229-9a86-88c31f3f04e2",
   "metadata": {},
   "source": [
    "class DataPreprocessor:\n",
    "    def preprocess_file(self, file: str) -> pd.DataFrame:\n",
    "        # Preprocessing logic here\n",
    "\n",
    "    def preprocess_str_column(self, series: pd.Series) -> pd.Series:\n",
    "        # Preprocessing logic here\n",
    "\n",
    "class DataValidator:\n",
    "    def validate_data(self):\n",
    "        # Validation logic here\n",
    "\n",
    "    def validate_col_names(self, attribute):\n",
    "        # Validation logic here\n",
    "\n",
    "    def validate_object_cols(self, attribute):\n",
    "        # Validation logic here\n",
    "\n",
    "class BaseCalculator:\n",
    "    def calculate_average_blanks(self):\n",
    "        # Common calculation logic here\n",
    "\n",
    "class Recovery(BaseCalculator):\n",
    "    # Recovery-specific methods here\n",
    "\n",
    "class CorrectionFactor(BaseCalculator):\n",
    "    # CorrectionFactor-specific methods here\n",
    "\n",
    "class ConcentrationCalculator(BaseCalculator):\n",
    "    # ConcentrationCalculator-specific methods here\n",
    "\n",
    "class FileReader:\n",
    "    def read_csv(self, file_path: str) -> pd.DataFrame:\n",
    "        # File reading logic here\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.file_reader = FileReader()\n",
    "        self.data_preprocessor = DataPreprocessor()\n",
    "        self.data_validator = DataValidator()\n",
    "        self.recovery_calculator = Recovery()\n",
    "        self.correction_factor_calculator = CorrectionFactor()\n",
    "        self.concentration_calculator = ConcentrationCalculator()\n",
    "\n",
    "    def execute(self, file_paths):\n",
    "        # Step 1: Read the files\n",
    "        files = self.file_reader.read_files(file_paths)\n",
    "\n",
    "        # Step 2: Preprocess the data\n",
    "        preprocessed_data = self.data_preprocessor.preprocess(files)\n",
    "\n",
    "        # Step 3: Validate the data\n",
    "        self.data_validator.validate(preprocessed_data)\n",
    "\n",
    "        # Step 4: Calculate recovery\n",
    "        recovery = self.recovery_calculator.calculate(preprocessed_data)\n",
    "\n",
    "        # Step 5: Calculate correction factors\n",
    "        correction_factors = self.correction_factor_calculator.calculate(preprocessed_data)\n",
    "\n",
    "        # Step 6: Calculate concentrations\n",
    "        concentrations = self.concentration_calculator.calculate(preprocessed_data, correction_factors)\n",
    "\n",
    "        return concentrations\n",
    "# Instantiate the Pipeline class\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Define the file paths\n",
    "file_paths = {\n",
    "    'quant_file': 'path_to_quant_file.csv',\n",
    "    'is_correspondence_file': 'path_to_is_correspondence_file.csv',\n",
    "    'sample_properties_file': 'path_to_sample_properties_file.csv',\n",
    "    'qc_file': 'path_to_qc_file.csv',\n",
    "    'is_concentration_file': 'path_to_is_concentration_file.csv'\n",
    "}\n",
    "\n",
    "# Use the pipeline to execute the entire process\n",
    "concentrations = pipeline.execute(file_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
